{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding Model with Instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_dataset_info(dataset):\n",
    "    info = dataset.info\n",
    "    dataset_name = info.dataset_name\n",
    "    splits_info = info.splits\n",
    "    features = info.features\n",
    "    print(f\"Dataset Name: {dataset_name}\")\n",
    "    print(\"Splits Info:\")\n",
    "    for split_name, split_info in splits_info.items():\n",
    "        num_examples = split_info.num_examples\n",
    "        print(f\" - Split: {split_name}, Num Examples: {num_examples}\")\n",
    "    print(\"Features:\")\n",
    "    for feature_name, feature_info in features.items():\n",
    "        print(f\" - {feature_name}: {feature_info}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import random\n",
    "from collections import defaultdict\n",
    "\n",
    "def get_dataset(dataset_name, train_size=0, test_size=0):  \n",
    "    # Load the dataset\n",
    "    dataset = load_dataset(dataset_name)\n",
    "    \n",
    "    # Access the train, test splits\n",
    "    train_dataset = dataset['train']\n",
    "    test_dataset = dataset['test']\n",
    "    \n",
    "    # Function to balance and shuffle a split\n",
    "    def shuffle(split, size):\n",
    "        if size == 0:\n",
    "            return split\n",
    "        label_to_indices = defaultdict(list)\n",
    "        for idx, example in enumerate(split):\n",
    "            label_to_indices[example['label']].append(idx)\n",
    "        \n",
    "        balanced_indices = []\n",
    "        for indices in label_to_indices.values():\n",
    "            if len(indices) >= size // len(label_to_indices):\n",
    "                balanced_indices.extend(random.sample(indices, size // len(label_to_indices)))\n",
    "            else:\n",
    "                balanced_indices.extend(indices)\n",
    "        \n",
    "        random.shuffle(balanced_indices)\n",
    "        return split.select(balanced_indices[:size])\n",
    "\n",
    "    if(train_size != 0):\n",
    "        train_dataset = train_dataset.shuffle(seed=42).select(range(train_size))\n",
    "    if(test_size != 0):\n",
    "        test_dataset = test_dataset.shuffle(seed=42).select(range(test_size))\n",
    "    # Shuffle and balance the datasets\n",
    "    # train_dataset = shuffle(train_dataset, train_size)\n",
    "    # test_dataset = shuffle(test_dataset, test_size)\n",
    "    \n",
    "    return train_dataset, test_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BERT - Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "from transformers.pipelines.pt_utils import KeyDataset\n",
    "import numpy as np\n",
    "\n",
    "def encode_Pipeline(model, dataset, max_length=512, use_cls=True):\n",
    "    key = \"text\"\n",
    "    data = KeyDataset(dataset, key)\n",
    "    pipe = model(data, return_tensors=True, truncation=True, padding=True, max_length=max_length)\n",
    "    embeddings=[]\n",
    "    for tensor in tqdm(pipe, desc=\"Encoding\"): \n",
    "        # Tensor Shape [batch_size, sequence_length, hidden_size]\n",
    "        if use_cls:\n",
    "            embedding = tensor[:, 0, :]\n",
    "        else:\n",
    "            embedding = tensor.mean(dim=1)\n",
    "        embeddings.append(embedding.squeeze())\n",
    "    return np.array(embeddings), np.array(dataset[\"label\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructor - Sentence Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_ST(model, dataset):\n",
    "    embeddings = []\n",
    "    texts = dataset[\"text\"]\n",
    "    instructions = dataset[\"instruction\"]\n",
    "    for text, instruction in tqdm(zip(texts, instructions),total=len(dataset), desc=\"Encoding\"):\n",
    "        embedding = model.encode([[instruction, text]])\n",
    "        embeddings.append(np.array(embedding).squeeze())\n",
    "    return np.array(embeddings), np.array(dataset[\"label\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### T5 - Transformer Sentence Piece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import T5Tokenizer, T5Model\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "def encode_T5(dataset, key=\"text\", truncation=True, padding=True, max_length=512, use_mean_pooling=True):\n",
    "    # Check if CUDA is available and set device accordingly\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    # Initialize the tokenizer and model\n",
    "    tokenizer = T5Tokenizer.from_pretrained(\"google-t5/t5-base\")\n",
    "    model = T5Model.from_pretrained(\"google-t5/t5-base\").to(device)\n",
    "    \n",
    "    embeddings = []\n",
    "    labels = []\n",
    "    \n",
    "    for data in tqdm(dataset, desc=\"Encoding text\"):\n",
    "        text = data[key]\n",
    "        label = data.get(\"label\", None)\n",
    "        \n",
    "        # Tokenize the input text\n",
    "        inputs = tokenizer(text, truncation=truncation, padding=padding, max_length=max_length, return_tensors=\"pt\")\n",
    "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "        \n",
    "        # Get encoder outputs\n",
    "        with torch.no_grad():\n",
    "            encoder_outputs = model.encoder(input_ids=inputs[\"input_ids\"], attention_mask=inputs[\"attention_mask\"])\n",
    "        \n",
    "        # Pooling to get a single vector for each input\n",
    "        if use_mean_pooling:\n",
    "            attention_mask = inputs['attention_mask']\n",
    "            last_hidden_state = encoder_outputs.last_hidden_state\n",
    "            mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n",
    "            sum_embeddings = torch.sum(last_hidden_state * mask_expanded, 1)\n",
    "            sum_mask = torch.clamp(mask_expanded.sum(1), min=1e-9)\n",
    "            embedding = sum_embeddings / sum_mask\n",
    "        else:\n",
    "            embedding = encoder_outputs.last_hidden_state[:, 0, :]\n",
    "        \n",
    "        embeddings.append(embedding.cpu().numpy().flatten())  # Flatten the embeddings\n",
    "        if label is not None:\n",
    "            labels.append(label)\n",
    "    \n",
    "    return np.array(embeddings), np.array(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augment Instruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapper_affixes(example, prefix, suffix):\n",
    "    example['text'] = prefix + example['text'] + suffix\n",
    "    return example\n",
    "\n",
    "def mapper_instruct(example, instruction):\n",
    "    example['instruction'] = instruction\n",
    "    return example\n",
    "\n",
    "def augment_dataset_Affix(dataset, prefix, suffix):\n",
    "    augmented_dataset = dataset.map(lambda x: mapper_affixes(x, prefix, suffix))\n",
    "    return augmented_dataset\n",
    "\n",
    "def augment_dataset_Inst(dataset, instruction):\n",
    "    augmented_dataset = dataset.map(lambda x: mapper_instruct(x, instruction))\n",
    "    return augmented_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "def evaluate(method, train_embeddings, test_embeddings, train_labels, test_labels):\n",
    "    if method == \"SVM\":\n",
    "        model = SVC(kernel='linear')\n",
    "        \n",
    "    elif method == \"MLP\":\n",
    "        model = MLPClassifier(hidden_layer_sizes=(100,), max_iter=300, alpha=1e-4,\n",
    "                          solver='sgd', verbose=1, random_state=1,\n",
    "                          learning_rate_init=.1)\n",
    "\n",
    "    model.fit(train_embeddings, train_labels)\n",
    "    predicted_labels = model.predict(test_embeddings)\n",
    "    accuracy = accuracy_score(test_labels, predicted_labels)\n",
    "    print(\"Report on \" + method + \": \")\n",
    "    print(classification_report(y_true = test_labels, y_pred = predicted_labels, digits=4))\n",
    "    return round(accuracy,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EmbedFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "def EmbedFlow_Bert_1(train_dataset, test_dataset, evaluator, prefix, suffix=''):\n",
    "    # Load Model\n",
    "    model = pipeline(\"feature-extraction\", model=\"google-bert/bert-base-uncased\", device=0)\n",
    "    \n",
    "    train_dataset = augment_dataset_Affix(train_dataset, prefix, suffix)\n",
    "    test_dataset = augment_dataset_Affix(test_dataset, prefix, suffix)\n",
    "\n",
    "    # Embed Dataset\n",
    "    train_embeddings, train_labels = encode_Pipeline(model, train_dataset, max_length=512, use_cls=True)\n",
    "    test_embeddings, test_labels = encode_Pipeline(model, test_dataset, use_cls=True)\n",
    "\n",
    "    # Evaluate\n",
    "    accuracy = evaluate(evaluator, train_embeddings, test_embeddings, train_labels, test_labels)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def EmbedFlow_Bert_2(train_dataset, test_dataset, evaluator, prefix, suffix=''):\n",
    "    # Load Model\n",
    "    model = pipeline(\"feature-extraction\", model=\"google-bert/bert-large-uncased\", device=0)\n",
    "    \n",
    "    train_dataset = augment_dataset_Affix(train_dataset, prefix, suffix)\n",
    "    test_dataset = augment_dataset_Affix(test_dataset, prefix, suffix)\n",
    "\n",
    "    # Embed Dataset\n",
    "    train_embeddings, train_labels = encode_Pipeline(model, train_dataset, max_length=512, use_cls=False)\n",
    "    test_embeddings, test_labels = encode_Pipeline(model, test_dataset, max_length=512, use_cls=False)\n",
    "\n",
    "    # Evaluate\n",
    "    accuracy = evaluate(evaluator, train_embeddings, test_embeddings, train_labels, test_labels)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "def EmbedFlow_Instructor(train_dataset, test_dataset, evaluator, instruction):\n",
    "    # Load Model\n",
    "    model = SentenceTransformer(\"hkunlp/instructor-large\")\n",
    "    \n",
    "    # Add Instruction\n",
    "    train_dataset = augment_dataset_Inst(train_dataset, instruction)\n",
    "    test_dataset = augment_dataset_Inst(test_dataset, instruction)\n",
    "\n",
    "    # Embed Dataset\n",
    "    train_embeddings, train_labels = encode_ST(model, train_dataset)\n",
    "    test_embeddings, test_labels = encode_ST(model, test_dataset)\n",
    "    \n",
    "    # Evaluate\n",
    "    accuracy = evaluate(evaluator, train_embeddings, test_embeddings, train_labels, test_labels)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def EmbedFlow_T5(train_dataset, test_dataset, evaluator, prefix, suffix=''):\n",
    "    # Load Model\n",
    "    model = pipeline(\"feature-extraction\", model=\"t5-base\", device=0)\n",
    "\n",
    "    # Add Instruction\n",
    "    train_dataset = augment_dataset_Affix(train_dataset, prefix, suffix)\n",
    "    test_dataset = augment_dataset_Affix(test_dataset, prefix, suffix)\n",
    "\n",
    "    # Embed Dataset\n",
    "    train_embeddings, train_labels = encode_T5(train_dataset)\n",
    "    test_embeddings, test_labels = encode_T5(test_dataset)\n",
    "    \n",
    "    # Evaluate\n",
    "    accuracy = evaluate(evaluator, train_embeddings, test_embeddings, train_labels, test_labels)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def EmbedFlow_GPT(train_dataset, test_dataset, evaluator, prefix, suffix=''):\n",
    "    # Load Model\n",
    "    model = pipeline(\"feature-extraction\", model=\"openai-community/gpt2\", device=0)\n",
    "  \n",
    "    # Add Instruction\n",
    "    train_dataset = augment_dataset_Affix(train_dataset, prefix, suffix)\n",
    "    test_dataset = augment_dataset_Affix(test_dataset, prefix, suffix)\n",
    "\n",
    "    # Embed Dataset\n",
    "    train_embeddings, train_labels = encode_Pipeline(model, train_dataset, use_cls=False)\n",
    "    test_embeddings, test_labels = encode_Pipeline(model, test_dataset, use_cls=False)\n",
    "    \n",
    "    # Evaluate\n",
    "    accuracy = evaluate(evaluator, train_embeddings, test_embeddings, train_labels, test_labels)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing\n",
    "Logging: [Google Sheet](https://docs.google.com/spreadsheets/d/1iBDq7C59G6olf_of_sTF5oCY3Itj6_kImzeUl3XMpd8/edit#gid=1587051763)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "instructions_old = ['',\n",
    "          'Movie Review: ', \n",
    "          'Restaurant Review: ', \n",
    "          'Sentiment Analysis: ', \n",
    "          'User Feedback: ', \n",
    "          'Customer Experience: ',\n",
    "          'Product Review: ',\n",
    "          'Service Feedback: ',\n",
    "          'Experience at: ',\n",
    "          'Abstract: ',\n",
    "          'Research Paper Abstract: ',\n",
    "          'Paper Summary: ']\n",
    "\n",
    "instructions_general = [\n",
    "    \"Sentiment Analysis: \",\n",
    "    \"Summarize: \",\n",
    "    \"Review: \",\n",
    "    \"Evaluate: \",\n",
    "    \"Analyze: \",\n",
    "    \"Represent the text for determining the sentiment: \",\n",
    "    \"Summarize the main points of the text for a concise overview: \",\n",
    "    \"Evaluate the text to classify its sentiment and key themes: \",\n",
    "    \"Analyze the text for sentiment classification and thematic understanding: \",\n",
    "    \"Classify the sentiment and summarize the content of the given text: \"\n",
    "]\n",
    "\n",
    "instructions_imdb=[\n",
    "    \"Movie Review: \",\n",
    "    \"Film Critique: \",\n",
    "    \"Cinema Opinion: \",\n",
    "    \"Film Feedback: \",\n",
    "    \"Review Analysis: \",\n",
    "    \"Represent the Review sentence for classifying emotion as positive or negative: \",\n",
    "    \"Evaluate the sentiment of the movie review sentence: \",\n",
    "    \"Analyze the review to determine if the sentiment is positive or negative: \",\n",
    "    \"Determine the emotional tone of the review for sentiment classification: \",\n",
    "    \"Classify the given movie review as either positive or negative: \",\n",
    "]\n",
    "instructions_yelp=[\n",
    "    \"Customer Experience at: \",\n",
    "    \"Opinion on: \",\n",
    "    \"Feed back on: \",\n",
    "    \"Restaurant Review: \",\n",
    "    \"User Feedback: \",\n",
    "    \"Describe the review in terms of customer satisfaction for the given place: \",\n",
    "    \"Evaluate the review to determine the customer's overall experience: \",\n",
    "    \"Analyze the review to classify the service quality as positive or negative: \",\n",
    "    \"Represent the customer's feedback on the establishment for sentiment analysis: \",\n",
    "    \"Determine the sentiment of the review, indicating whether the experience was positive or negative: \",\n",
    "]\n",
    "\n",
    "instructions_arXiv = [\n",
    "    \"Paper Summary: \",\n",
    "    \"Overview: \",\n",
    "    \"Abstract: \",\n",
    "    \"Key points: \",\n",
    "    \"Main findings: \",\n",
    "    \"Please read the following research paper abstract and summarize the key points and findings discussed: \",\n",
    "    \"Analyze the following abstract from a research paper and provide a detailed overview of its main ideas and conclusions: \",\n",
    "    \"Review the following abstract of a research paper and highlight the primary methodologies and results presented: \",\n",
    "    \"Examine the following abstract from a scientific paper and summarize the main topics and discoveries described: \",\n",
    "    \"Process the following research paper abstract and provide a concise summary of the core themes and contributions of the study: \"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing dataset: stanfordnlp/imdb, instruction: 'Sentiment Analysis: '\n",
      "Bert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding: 100%|██████████| 5/5 [00:00<00:00, 154.55it/s]\n",
      "Encoding: 100%|██████████| 5/5 [00:00<00:00, 172.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report on SVM: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000         2\n",
      "           1     0.5000    0.6667    0.5714         3\n",
      "\n",
      "    accuracy                         0.4000         5\n",
      "   macro avg     0.2500    0.3333    0.2857         5\n",
      "weighted avg     0.3000    0.4000    0.3429         5\n",
      "\n",
      "Bert2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding: 100%|██████████| 5/5 [00:00<00:00, 53.38it/s]\n",
      "Encoding: 100%|██████████| 5/5 [00:00<00:00, 63.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report on SVM: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5000    0.5000    0.5000         2\n",
      "           1     0.6667    0.6667    0.6667         3\n",
      "\n",
      "    accuracy                         0.6000         5\n",
      "   macro avg     0.5833    0.5833    0.5833         5\n",
      "weighted avg     0.6000    0.6000    0.6000         5\n",
      "\n",
      "Instructor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding: 100%|██████████| 5/5 [00:00<00:00, 55.74it/s]\n",
      "Encoding: 100%|██████████| 5/5 [00:00<00:00, 57.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report on SVM: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000         2\n",
      "           1     0.6000    1.0000    0.7500         3\n",
      "\n",
      "    accuracy                         0.6000         5\n",
      "   macro avg     0.3000    0.5000    0.3750         5\n",
      "weighted avg     0.3600    0.6000    0.4500         5\n",
      "\n",
      "T5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Encoding text: 100%|██████████| 5/5 [00:00<00:00, 154.59it/s]\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Encoding text: 100%|██████████| 5/5 [00:00<00:00, 161.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report on SVM: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000         2\n",
      "           1     0.6000    1.0000    0.7500         3\n",
      "\n",
      "    accuracy                         0.6000         5\n",
      "   macro avg     0.3000    0.5000    0.3750         5\n",
      "weighted avg     0.3600    0.6000    0.4500         5\n",
      "\n",
      "GPT2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding: 100%|██████████| 5/5 [00:00<00:00, 56.36it/s]\n",
      "Encoding: 100%|██████████| 5/5 [00:00<00:00, 73.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report on SVM: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000         2\n",
      "           1     0.5000    0.6667    0.5714         3\n",
      "\n",
      "    accuracy                         0.4000         5\n",
      "   macro avg     0.2500    0.3333    0.2857         5\n",
      "weighted avg     0.3000    0.4000    0.3429         5\n",
      "\n",
      "Processing dataset: stanfordnlp/imdb, instruction: 'Summarize: '\n",
      "Bert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding: 100%|██████████| 5/5 [00:00<00:00, 172.19it/s]\n",
      "Encoding: 100%|██████████| 5/5 [00:00<00:00, 188.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report on SVM: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000         2\n",
      "           1     0.6000    1.0000    0.7500         3\n",
      "\n",
      "    accuracy                         0.6000         5\n",
      "   macro avg     0.3000    0.5000    0.3750         5\n",
      "weighted avg     0.3600    0.6000    0.4500         5\n",
      "\n",
      "Bert2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding: 100%|██████████| 5/5 [00:00<00:00, 55.25it/s]\n",
      "Encoding: 100%|██████████| 5/5 [00:00<00:00, 79.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report on SVM: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.3333    0.5000    0.4000         2\n",
      "           1     0.5000    0.3333    0.4000         3\n",
      "\n",
      "    accuracy                         0.4000         5\n",
      "   macro avg     0.4167    0.4167    0.4000         5\n",
      "weighted avg     0.4333    0.4000    0.4000         5\n",
      "\n",
      "Instructor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding: 100%|██████████| 5/5 [00:00<00:00, 56.79it/s]\n",
      "Encoding: 100%|██████████| 5/5 [00:00<00:00, 58.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report on SVM: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000         2\n",
      "           1     0.6000    1.0000    0.7500         3\n",
      "\n",
      "    accuracy                         0.6000         5\n",
      "   macro avg     0.3000    0.5000    0.3750         5\n",
      "weighted avg     0.3600    0.6000    0.4500         5\n",
      "\n",
      "T5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Encoding text: 100%|██████████| 5/5 [00:00<00:00, 147.41it/s]\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Encoding text: 100%|██████████| 5/5 [00:00<00:00, 123.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report on SVM: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000         2\n",
      "           1     0.5000    0.6667    0.5714         3\n",
      "\n",
      "    accuracy                         0.4000         5\n",
      "   macro avg     0.2500    0.3333    0.2857         5\n",
      "weighted avg     0.3000    0.4000    0.3429         5\n",
      "\n",
      "GPT2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding: 100%|██████████| 5/5 [00:00<00:00, 44.98it/s]\n",
      "Encoding: 100%|██████████| 5/5 [00:00<00:00, 48.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report on SVM: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000         2\n",
      "           1     0.5000    0.6667    0.5714         3\n",
      "\n",
      "    accuracy                         0.4000         5\n",
      "   macro avg     0.2500    0.3333    0.2857         5\n",
      "weighted avg     0.3000    0.4000    0.3429         5\n",
      "\n",
      "Processing dataset: stanfordnlp/imdb, instruction: 'Review: '\n",
      "Bert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding: 100%|██████████| 5/5 [00:00<00:00, 136.79it/s]\n",
      "Encoding: 100%|██████████| 5/5 [00:00<00:00, 147.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report on SVM: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000         2\n",
      "           1     0.6000    1.0000    0.7500         3\n",
      "\n",
      "    accuracy                         0.6000         5\n",
      "   macro avg     0.3000    0.5000    0.3750         5\n",
      "weighted avg     0.3600    0.6000    0.4500         5\n",
      "\n",
      "Bert2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding: 100%|██████████| 5/5 [00:00<00:00, 47.72it/s]\n",
      "Encoding: 100%|██████████| 5/5 [00:00<00:00, 56.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report on SVM: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5000    0.5000    0.5000         2\n",
      "           1     0.6667    0.6667    0.6667         3\n",
      "\n",
      "    accuracy                         0.6000         5\n",
      "   macro avg     0.5833    0.5833    0.5833         5\n",
      "weighted avg     0.6000    0.6000    0.6000         5\n",
      "\n",
      "Instructor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding: 100%|██████████| 5/5 [00:00<00:00, 59.26it/s]\n",
      "Encoding: 100%|██████████| 5/5 [00:00<00:00, 58.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report on SVM: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000         2\n",
      "           1     0.6000    1.0000    0.7500         3\n",
      "\n",
      "    accuracy                         0.6000         5\n",
      "   macro avg     0.3000    0.5000    0.3750         5\n",
      "weighted avg     0.3600    0.6000    0.4500         5\n",
      "\n",
      "T5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Encoding text: 100%|██████████| 5/5 [00:00<00:00, 149.01it/s]\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Encoding text: 100%|██████████| 5/5 [00:00<00:00, 123.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report on SVM: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000         2\n",
      "           1     0.6000    1.0000    0.7500         3\n",
      "\n",
      "    accuracy                         0.6000         5\n",
      "   macro avg     0.3000    0.5000    0.3750         5\n",
      "weighted avg     0.3600    0.6000    0.4500         5\n",
      "\n",
      "GPT2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding: 100%|██████████| 5/5 [00:00<00:00, 52.67it/s]\n",
      "Encoding: 100%|██████████| 5/5 [00:00<00:00, 53.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report on SVM: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000         2\n",
      "           1     0.5000    0.6667    0.5714         3\n",
      "\n",
      "    accuracy                         0.4000         5\n",
      "   macro avg     0.2500    0.3333    0.2857         5\n",
      "weighted avg     0.3000    0.4000    0.3429         5\n",
      "\n",
      "Processing dataset: stanfordnlp/imdb, instruction: 'Evaluate: '\n",
      "Bert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding: 100%|██████████| 5/5 [00:00<00:00, 142.08it/s]\n",
      "Encoding: 100%|██████████| 5/5 [00:00<00:00, 158.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report on SVM: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000         2\n",
      "           1     0.6000    1.0000    0.7500         3\n",
      "\n",
      "    accuracy                         0.6000         5\n",
      "   macro avg     0.3000    0.5000    0.3750         5\n",
      "weighted avg     0.3600    0.6000    0.4500         5\n",
      "\n",
      "Bert2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding: 100%|██████████| 5/5 [00:00<00:00, 51.99it/s]\n",
      "Encoding: 100%|██████████| 5/5 [00:00<00:00, 65.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report on SVM: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.3333    0.5000    0.4000         2\n",
      "           1     0.5000    0.3333    0.4000         3\n",
      "\n",
      "    accuracy                         0.4000         5\n",
      "   macro avg     0.4167    0.4167    0.4000         5\n",
      "weighted avg     0.4333    0.4000    0.4000         5\n",
      "\n",
      "Instructor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding: 100%|██████████| 5/5 [00:00<00:00, 57.01it/s]\n",
      "Encoding: 100%|██████████| 5/5 [00:00<00:00, 59.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report on SVM: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000         2\n",
      "           1     0.6000    1.0000    0.7500         3\n",
      "\n",
      "    accuracy                         0.6000         5\n",
      "   macro avg     0.3000    0.5000    0.3750         5\n",
      "weighted avg     0.3600    0.6000    0.4500         5\n",
      "\n",
      "T5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Encoding text: 100%|██████████| 5/5 [00:00<00:00, 149.62it/s]\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Encoding text: 100%|██████████| 5/5 [00:00<00:00, 115.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report on SVM: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000         2\n",
      "           1     0.6000    1.0000    0.7500         3\n",
      "\n",
      "    accuracy                         0.6000         5\n",
      "   macro avg     0.3000    0.5000    0.3750         5\n",
      "weighted avg     0.3600    0.6000    0.4500         5\n",
      "\n",
      "GPT2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding: 100%|██████████| 5/5 [00:00<00:00, 45.36it/s]\n",
      "Encoding: 100%|██████████| 5/5 [00:00<00:00, 67.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report on SVM: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000         2\n",
      "           1     0.5000    0.6667    0.5714         3\n",
      "\n",
      "    accuracy                         0.4000         5\n",
      "   macro avg     0.2500    0.3333    0.2857         5\n",
      "weighted avg     0.3000    0.4000    0.3429         5\n",
      "\n",
      "Processing dataset: stanfordnlp/imdb, instruction: 'Analyze: '\n",
      "Bert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding: 100%|██████████| 5/5 [00:00<00:00, 165.88it/s]\n",
      "Encoding: 100%|██████████| 5/5 [00:00<00:00, 169.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report on SVM: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000         2\n",
      "           1     0.5000    0.6667    0.5714         3\n",
      "\n",
      "    accuracy                         0.4000         5\n",
      "   macro avg     0.2500    0.3333    0.2857         5\n",
      "weighted avg     0.3000    0.4000    0.3429         5\n",
      "\n",
      "Bert2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding: 100%|██████████| 5/5 [00:00<00:00, 62.85it/s]\n",
      "Encoding: 100%|██████████| 5/5 [00:00<00:00, 73.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report on SVM: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.3333    0.5000    0.4000         2\n",
      "           1     0.5000    0.3333    0.4000         3\n",
      "\n",
      "    accuracy                         0.4000         5\n",
      "   macro avg     0.4167    0.4167    0.4000         5\n",
      "weighted avg     0.4333    0.4000    0.4000         5\n",
      "\n",
      "Instructor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding: 100%|██████████| 5/5 [00:00<00:00, 56.19it/s]\n",
      "Encoding: 100%|██████████| 5/5 [00:00<00:00, 57.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report on SVM: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000         2\n",
      "           1     0.6000    1.0000    0.7500         3\n",
      "\n",
      "    accuracy                         0.6000         5\n",
      "   macro avg     0.3000    0.5000    0.3750         5\n",
      "weighted avg     0.3600    0.6000    0.4500         5\n",
      "\n",
      "T5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Encoding text: 100%|██████████| 5/5 [00:00<00:00, 151.95it/s]\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Encoding text: 100%|██████████| 5/5 [00:00<00:00, 121.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report on SVM: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000         2\n",
      "           1     0.6000    1.0000    0.7500         3\n",
      "\n",
      "    accuracy                         0.6000         5\n",
      "   macro avg     0.3000    0.5000    0.3750         5\n",
      "weighted avg     0.3600    0.6000    0.4500         5\n",
      "\n",
      "GPT2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding: 100%|██████████| 5/5 [00:00<00:00, 59.68it/s]\n",
      "Encoding: 100%|██████████| 5/5 [00:00<00:00, 86.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report on SVM: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000         2\n",
      "           1     0.5000    0.6667    0.5714         3\n",
      "\n",
      "    accuracy                         0.4000         5\n",
      "   macro avg     0.2500    0.3333    0.2857         5\n",
      "weighted avg     0.3000    0.4000    0.3429         5\n",
      "\n",
      "Processing dataset: stanfordnlp/imdb, instruction: 'Represent the text for determining the sentiment: '\n",
      "Bert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding: 100%|██████████| 5/5 [00:00<00:00, 174.09it/s]\n",
      "Encoding: 100%|██████████| 5/5 [00:00<00:00, 135.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report on SVM: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000         2\n",
      "           1     0.5000    0.6667    0.5714         3\n",
      "\n",
      "    accuracy                         0.4000         5\n",
      "   macro avg     0.2500    0.3333    0.2857         5\n",
      "weighted avg     0.3000    0.4000    0.3429         5\n",
      "\n",
      "Bert2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding: 100%|██████████| 5/5 [00:00<00:00, 48.69it/s]\n",
      "Encoding: 100%|██████████| 5/5 [00:00<00:00, 77.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report on SVM: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5000    0.5000    0.5000         2\n",
      "           1     0.6667    0.6667    0.6667         3\n",
      "\n",
      "    accuracy                         0.6000         5\n",
      "   macro avg     0.5833    0.5833    0.5833         5\n",
      "weighted avg     0.6000    0.6000    0.6000         5\n",
      "\n",
      "Instructor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding: 100%|██████████| 5/5 [00:00<00:00, 40.29it/s]\n",
      "Encoding: 100%|██████████| 5/5 [00:00<00:00, 52.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report on SVM: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000         2\n",
      "           1     0.6000    1.0000    0.7500         3\n",
      "\n",
      "    accuracy                         0.6000         5\n",
      "   macro avg     0.3000    0.5000    0.3750         5\n",
      "weighted avg     0.3600    0.6000    0.4500         5\n",
      "\n",
      "T5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Encoding text: 100%|██████████| 5/5 [00:00<00:00, 160.54it/s]\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Encoding text: 100%|██████████| 5/5 [00:00<00:00, 133.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report on SVM: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000         2\n",
      "           1     0.6000    1.0000    0.7500         3\n",
      "\n",
      "    accuracy                         0.6000         5\n",
      "   macro avg     0.3000    0.5000    0.3750         5\n",
      "weighted avg     0.3600    0.6000    0.4500         5\n",
      "\n",
      "GPT2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding: 100%|██████████| 5/5 [00:00<00:00, 53.31it/s]\n",
      "Encoding: 100%|██████████| 5/5 [00:00<00:00, 69.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report on SVM: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000         2\n",
      "           1     0.5000    0.6667    0.5714         3\n",
      "\n",
      "    accuracy                         0.4000         5\n",
      "   macro avg     0.2500    0.3333    0.2857         5\n",
      "weighted avg     0.3000    0.4000    0.3429         5\n",
      "\n",
      "Processing dataset: stanfordnlp/imdb, instruction: 'Summarize the main points of the text for a concise overview: '\n",
      "Bert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding: 100%|██████████| 5/5 [00:00<00:00, 162.28it/s]\n",
      "Encoding: 100%|██████████| 5/5 [00:00<00:00, 155.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report on SVM: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000         2\n",
      "           1     0.5000    0.6667    0.5714         3\n",
      "\n",
      "    accuracy                         0.4000         5\n",
      "   macro avg     0.2500    0.3333    0.2857         5\n",
      "weighted avg     0.3000    0.4000    0.3429         5\n",
      "\n",
      "Bert2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding: 100%|██████████| 5/5 [00:00<00:00, 63.21it/s]\n",
      "Encoding: 100%|██████████| 5/5 [00:00<00:00, 62.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report on SVM: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5000    0.5000    0.5000         2\n",
      "           1     0.6667    0.6667    0.6667         3\n",
      "\n",
      "    accuracy                         0.6000         5\n",
      "   macro avg     0.5833    0.5833    0.5833         5\n",
      "weighted avg     0.6000    0.6000    0.6000         5\n",
      "\n",
      "Instructor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding: 100%|██████████| 5/5 [00:00<00:00, 56.07it/s]\n",
      "Encoding: 100%|██████████| 5/5 [00:00<00:00, 58.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report on SVM: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000         2\n",
      "           1     0.6000    1.0000    0.7500         3\n",
      "\n",
      "    accuracy                         0.6000         5\n",
      "   macro avg     0.3000    0.5000    0.3750         5\n",
      "weighted avg     0.3600    0.6000    0.4500         5\n",
      "\n",
      "T5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Encoding text: 100%|██████████| 5/5 [00:00<00:00, 160.95it/s]\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Encoding text: 100%|██████████| 5/5 [00:00<00:00, 113.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report on SVM: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000         2\n",
      "           1     0.6000    1.0000    0.7500         3\n",
      "\n",
      "    accuracy                         0.6000         5\n",
      "   macro avg     0.3000    0.5000    0.3750         5\n",
      "weighted avg     0.3600    0.6000    0.4500         5\n",
      "\n",
      "GPT2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding: 100%|██████████| 5/5 [00:00<00:00, 50.93it/s]\n",
      "Encoding: 100%|██████████| 5/5 [00:00<00:00, 59.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report on SVM: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000         2\n",
      "           1     0.5000    0.6667    0.5714         3\n",
      "\n",
      "    accuracy                         0.4000         5\n",
      "   macro avg     0.2500    0.3333    0.2857         5\n",
      "weighted avg     0.3000    0.4000    0.3429         5\n",
      "\n",
      "Processing dataset: stanfordnlp/imdb, instruction: 'Evaluate the text to classify its sentiment and key themes: '\n",
      "Bert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding: 100%|██████████| 5/5 [00:00<00:00, 134.67it/s]\n",
      "Encoding: 100%|██████████| 5/5 [00:00<00:00, 148.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report on SVM: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000         2\n",
      "           1     0.5000    0.6667    0.5714         3\n",
      "\n",
      "    accuracy                         0.4000         5\n",
      "   macro avg     0.2500    0.3333    0.2857         5\n",
      "weighted avg     0.3000    0.4000    0.3429         5\n",
      "\n",
      "Bert2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding: 100%|██████████| 5/5 [00:00<00:00, 48.94it/s]\n",
      "Encoding: 100%|██████████| 5/5 [00:00<00:00, 59.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report on SVM: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5000    0.5000    0.5000         2\n",
      "           1     0.6667    0.6667    0.6667         3\n",
      "\n",
      "    accuracy                         0.6000         5\n",
      "   macro avg     0.5833    0.5833    0.5833         5\n",
      "weighted avg     0.6000    0.6000    0.6000         5\n",
      "\n",
      "Instructor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding: 100%|██████████| 5/5 [00:00<00:00, 56.55it/s]\n",
      "Encoding: 100%|██████████| 5/5 [00:00<00:00, 56.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report on SVM: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000         2\n",
      "           1     0.6000    1.0000    0.7500         3\n",
      "\n",
      "    accuracy                         0.6000         5\n",
      "   macro avg     0.3000    0.5000    0.3750         5\n",
      "weighted avg     0.3600    0.6000    0.4500         5\n",
      "\n",
      "T5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Encoding text: 100%|██████████| 5/5 [00:00<00:00, 153.71it/s]\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Encoding text: 100%|██████████| 5/5 [00:00<00:00, 137.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report on SVM: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000         2\n",
      "           1     0.6000    1.0000    0.7500         3\n",
      "\n",
      "    accuracy                         0.6000         5\n",
      "   macro avg     0.3000    0.5000    0.3750         5\n",
      "weighted avg     0.3600    0.6000    0.4500         5\n",
      "\n",
      "GPT2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding: 100%|██████████| 5/5 [00:00<00:00, 47.87it/s]\n",
      "Encoding: 100%|██████████| 5/5 [00:00<00:00, 59.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report on SVM: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000         2\n",
      "           1     0.6000    1.0000    0.7500         3\n",
      "\n",
      "    accuracy                         0.6000         5\n",
      "   macro avg     0.3000    0.5000    0.3750         5\n",
      "weighted avg     0.3600    0.6000    0.4500         5\n",
      "\n",
      "Processing dataset: stanfordnlp/imdb, instruction: 'Analyze the text for sentiment classification and thematic understanding: '\n",
      "Bert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding: 100%|██████████| 5/5 [00:00<00:00, 138.69it/s]\n",
      "Encoding: 100%|██████████| 5/5 [00:00<00:00, 150.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report on SVM: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000         2\n",
      "           1     0.6000    1.0000    0.7500         3\n",
      "\n",
      "    accuracy                         0.6000         5\n",
      "   macro avg     0.3000    0.5000    0.3750         5\n",
      "weighted avg     0.3600    0.6000    0.4500         5\n",
      "\n",
      "Bert2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding: 100%|██████████| 5/5 [00:00<00:00, 53.46it/s]\n",
      "Encoding: 100%|██████████| 5/5 [00:00<00:00, 79.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report on SVM: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5000    0.5000    0.5000         2\n",
      "           1     0.6667    0.6667    0.6667         3\n",
      "\n",
      "    accuracy                         0.6000         5\n",
      "   macro avg     0.5833    0.5833    0.5833         5\n",
      "weighted avg     0.6000    0.6000    0.6000         5\n",
      "\n",
      "Instructor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding: 100%|██████████| 5/5 [00:00<00:00, 56.82it/s]\n",
      "Encoding: 100%|██████████| 5/5 [00:00<00:00, 59.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report on SVM: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000         2\n",
      "           1     0.6000    1.0000    0.7500         3\n",
      "\n",
      "    accuracy                         0.6000         5\n",
      "   macro avg     0.3000    0.5000    0.3750         5\n",
      "weighted avg     0.3600    0.6000    0.4500         5\n",
      "\n",
      "T5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Encoding text: 100%|██████████| 5/5 [00:00<00:00, 160.25it/s]\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Encoding text: 100%|██████████| 5/5 [00:00<00:00, 119.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report on SVM: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000         2\n",
      "           1     0.6000    1.0000    0.7500         3\n",
      "\n",
      "    accuracy                         0.6000         5\n",
      "   macro avg     0.3000    0.5000    0.3750         5\n",
      "weighted avg     0.3600    0.6000    0.4500         5\n",
      "\n",
      "GPT2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding: 100%|██████████| 5/5 [00:00<00:00, 50.91it/s]\n",
      "Encoding: 100%|██████████| 5/5 [00:00<00:00, 64.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report on SVM: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000         2\n",
      "           1     0.6000    1.0000    0.7500         3\n",
      "\n",
      "    accuracy                         0.6000         5\n",
      "   macro avg     0.3000    0.5000    0.3750         5\n",
      "weighted avg     0.3600    0.6000    0.4500         5\n",
      "\n",
      "Processing dataset: stanfordnlp/imdb, instruction: 'Classify the sentiment and summarize the content of the given text: '\n",
      "Bert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding: 100%|██████████| 5/5 [00:00<00:00, 123.28it/s]\n",
      "Encoding: 100%|██████████| 5/5 [00:00<00:00, 134.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report on SVM: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000         2\n",
      "           1     0.5000    0.6667    0.5714         3\n",
      "\n",
      "    accuracy                         0.4000         5\n",
      "   macro avg     0.2500    0.3333    0.2857         5\n",
      "weighted avg     0.3000    0.4000    0.3429         5\n",
      "\n",
      "Bert2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding: 100%|██████████| 5/5 [00:00<00:00, 46.16it/s]\n",
      "Encoding: 100%|██████████| 5/5 [00:00<00:00, 48.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report on SVM: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5000    0.5000    0.5000         2\n",
      "           1     0.6667    0.6667    0.6667         3\n",
      "\n",
      "    accuracy                         0.6000         5\n",
      "   macro avg     0.5833    0.5833    0.5833         5\n",
      "weighted avg     0.6000    0.6000    0.6000         5\n",
      "\n",
      "Instructor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding: 100%|██████████| 5/5 [00:00<00:00, 57.40it/s]\n",
      "Encoding: 100%|██████████| 5/5 [00:00<00:00, 52.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report on SVM: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000         2\n",
      "           1     0.6000    1.0000    0.7500         3\n",
      "\n",
      "    accuracy                         0.6000         5\n",
      "   macro avg     0.3000    0.5000    0.3750         5\n",
      "weighted avg     0.3600    0.6000    0.4500         5\n",
      "\n",
      "T5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Encoding text: 100%|██████████| 5/5 [00:00<00:00, 138.47it/s]\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Encoding text: 100%|██████████| 5/5 [00:00<00:00, 123.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report on SVM: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000         2\n",
      "           1     0.6000    1.0000    0.7500         3\n",
      "\n",
      "    accuracy                         0.6000         5\n",
      "   macro avg     0.3000    0.5000    0.3750         5\n",
      "weighted avg     0.3600    0.6000    0.4500         5\n",
      "\n",
      "GPT2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding: 100%|██████████| 5/5 [00:00<00:00, 42.93it/s]\n",
      "Encoding: 100%|██████████| 5/5 [00:00<00:00, 55.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report on SVM: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000         2\n",
      "           1     0.6000    1.0000    0.7500         3\n",
      "\n",
      "    accuracy                         0.6000         5\n",
      "   macro avg     0.3000    0.5000    0.3750         5\n",
      "weighted avg     0.3600    0.6000    0.4500         5\n",
      "\n",
      "Processing dataset: stanfordnlp/imdb, instruction: 'Movie Review: '\n",
      "Bert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding: 100%|██████████| 5/5 [00:00<00:00, 116.51it/s]\n",
      "Encoding: 100%|██████████| 5/5 [00:00<00:00, 153.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report on SVM: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000         2\n",
      "           1     0.6000    1.0000    0.7500         3\n",
      "\n",
      "    accuracy                         0.6000         5\n",
      "   macro avg     0.3000    0.5000    0.3750         5\n",
      "weighted avg     0.3600    0.6000    0.4500         5\n",
      "\n",
      "Bert2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding: 100%|██████████| 5/5 [00:00<00:00, 46.10it/s]\n",
      "Encoding: 100%|██████████| 5/5 [00:00<00:00, 54.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report on SVM: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5000    0.5000    0.5000         2\n",
      "           1     0.6667    0.6667    0.6667         3\n",
      "\n",
      "    accuracy                         0.6000         5\n",
      "   macro avg     0.5833    0.5833    0.5833         5\n",
      "weighted avg     0.6000    0.6000    0.6000         5\n",
      "\n",
      "Instructor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding: 100%|██████████| 5/5 [00:00<00:00, 57.58it/s]\n",
      "Encoding: 100%|██████████| 5/5 [00:00<00:00, 52.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report on SVM: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000         2\n",
      "           1     0.6000    1.0000    0.7500         3\n",
      "\n",
      "    accuracy                         0.6000         5\n",
      "   macro avg     0.3000    0.5000    0.3750         5\n",
      "weighted avg     0.3600    0.6000    0.4500         5\n",
      "\n",
      "T5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Encoding text: 100%|██████████| 5/5 [00:00<00:00, 153.28it/s]\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Encoding text: 100%|██████████| 5/5 [00:00<00:00, 104.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report on SVM: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000         2\n",
      "           1     0.6000    1.0000    0.7500         3\n",
      "\n",
      "    accuracy                         0.6000         5\n",
      "   macro avg     0.3000    0.5000    0.3750         5\n",
      "weighted avg     0.3600    0.6000    0.4500         5\n",
      "\n",
      "GPT2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding: 100%|██████████| 5/5 [00:00<00:00, 48.43it/s]\n",
      "Encoding: 100%|██████████| 5/5 [00:00<00:00, 63.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report on SVM: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000         2\n",
      "           1     0.5000    0.6667    0.5714         3\n",
      "\n",
      "    accuracy                         0.4000         5\n",
      "   macro avg     0.2500    0.3333    0.2857         5\n",
      "weighted avg     0.3000    0.4000    0.3429         5\n",
      "\n",
      "Processing dataset: stanfordnlp/imdb, instruction: 'Film Critique: '\n",
      "Bert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding: 100%|██████████| 5/5 [00:00<00:00, 113.36it/s]\n",
      "Encoding: 100%|██████████| 5/5 [00:00<00:00, 121.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report on SVM: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000         2\n",
      "           1     0.5000    0.6667    0.5714         3\n",
      "\n",
      "    accuracy                         0.4000         5\n",
      "   macro avg     0.2500    0.3333    0.2857         5\n",
      "weighted avg     0.3000    0.4000    0.3429         5\n",
      "\n",
      "Bert2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding: 100%|██████████| 5/5 [00:00<00:00, 46.82it/s]\n",
      "Encoding: 100%|██████████| 5/5 [00:00<00:00, 57.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report on SVM: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5000    0.5000    0.5000         2\n",
      "           1     0.6667    0.6667    0.6667         3\n",
      "\n",
      "    accuracy                         0.6000         5\n",
      "   macro avg     0.5833    0.5833    0.5833         5\n",
      "weighted avg     0.6000    0.6000    0.6000         5\n",
      "\n",
      "Instructor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding: 100%|██████████| 5/5 [00:00<00:00, 55.56it/s]\n",
      "Encoding: 100%|██████████| 5/5 [00:00<00:00, 57.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report on SVM: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000         2\n",
      "           1     0.6000    1.0000    0.7500         3\n",
      "\n",
      "    accuracy                         0.6000         5\n",
      "   macro avg     0.3000    0.5000    0.3750         5\n",
      "weighted avg     0.3600    0.6000    0.4500         5\n",
      "\n",
      "T5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Encoding text: 100%|██████████| 5/5 [00:00<00:00, 105.12it/s]\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Encoding text: 100%|██████████| 5/5 [00:00<00:00, 121.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report on SVM: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000         2\n",
      "           1     0.6000    1.0000    0.7500         3\n",
      "\n",
      "    accuracy                         0.6000         5\n",
      "   macro avg     0.3000    0.5000    0.3750         5\n",
      "weighted avg     0.3600    0.6000    0.4500         5\n",
      "\n",
      "GPT2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding: 100%|██████████| 5/5 [00:00<00:00, 48.69it/s]\n",
      "Encoding: 100%|██████████| 5/5 [00:00<00:00, 56.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report on SVM: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000         2\n",
      "           1     0.5000    0.6667    0.5714         3\n",
      "\n",
      "    accuracy                         0.4000         5\n",
      "   macro avg     0.2500    0.3333    0.2857         5\n",
      "weighted avg     0.3000    0.4000    0.3429         5\n",
      "\n",
      "Processing dataset: stanfordnlp/imdb, instruction: 'Cinema Opinion: '\n",
      "Bert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding: 100%|██████████| 5/5 [00:00<00:00, 153.49it/s]\n",
      "Encoding: 100%|██████████| 5/5 [00:00<00:00, 158.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report on SVM: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000         2\n",
      "           1     0.6000    1.0000    0.7500         3\n",
      "\n",
      "    accuracy                         0.6000         5\n",
      "   macro avg     0.3000    0.5000    0.3750         5\n",
      "weighted avg     0.3600    0.6000    0.4500         5\n",
      "\n",
      "Bert2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding: 100%|██████████| 5/5 [00:00<00:00, 53.43it/s]\n",
      "Encoding: 100%|██████████| 5/5 [00:00<00:00, 69.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report on SVM: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5000    0.5000    0.5000         2\n",
      "           1     0.6667    0.6667    0.6667         3\n",
      "\n",
      "    accuracy                         0.6000         5\n",
      "   macro avg     0.5833    0.5833    0.5833         5\n",
      "weighted avg     0.6000    0.6000    0.6000         5\n",
      "\n",
      "Instructor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding: 100%|██████████| 5/5 [00:00<00:00, 53.62it/s]\n",
      "Encoding: 100%|██████████| 5/5 [00:00<00:00, 58.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report on SVM: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000         2\n",
      "           1     0.6000    1.0000    0.7500         3\n",
      "\n",
      "    accuracy                         0.6000         5\n",
      "   macro avg     0.3000    0.5000    0.3750         5\n",
      "weighted avg     0.3600    0.6000    0.4500         5\n",
      "\n",
      "T5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Encoding text: 100%|██████████| 5/5 [00:00<00:00, 114.49it/s]\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Encoding text: 100%|██████████| 5/5 [00:00<00:00, 125.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report on SVM: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000         2\n",
      "           1     0.5000    0.6667    0.5714         3\n",
      "\n",
      "    accuracy                         0.4000         5\n",
      "   macro avg     0.2500    0.3333    0.2857         5\n",
      "weighted avg     0.3000    0.4000    0.3429         5\n",
      "\n",
      "GPT2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding: 100%|██████████| 5/5 [00:00<00:00, 47.27it/s]\n",
      "Encoding: 100%|██████████| 5/5 [00:00<00:00, 60.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report on SVM: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000         2\n",
      "           1     0.5000    0.6667    0.5714         3\n",
      "\n",
      "    accuracy                         0.4000         5\n",
      "   macro avg     0.2500    0.3333    0.2857         5\n",
      "weighted avg     0.3000    0.4000    0.3429         5\n",
      "\n",
      "Processing dataset: stanfordnlp/imdb, instruction: 'Film Feedback: '\n",
      "Bert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding: 100%|██████████| 5/5 [00:00<00:00, 158.41it/s]\n",
      "Encoding: 100%|██████████| 5/5 [00:00<00:00, 172.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report on SVM: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000         2\n",
      "           1     0.5000    0.6667    0.5714         3\n",
      "\n",
      "    accuracy                         0.4000         5\n",
      "   macro avg     0.2500    0.3333    0.2857         5\n",
      "weighted avg     0.3000    0.4000    0.3429         5\n",
      "\n",
      "Bert2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding: 100%|██████████| 5/5 [00:00<00:00, 56.72it/s]\n",
      "Encoding: 100%|██████████| 5/5 [00:00<00:00, 72.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report on SVM: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5000    0.5000    0.5000         2\n",
      "           1     0.6667    0.6667    0.6667         3\n",
      "\n",
      "    accuracy                         0.6000         5\n",
      "   macro avg     0.5833    0.5833    0.5833         5\n",
      "weighted avg     0.6000    0.6000    0.6000         5\n",
      "\n",
      "Instructor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding: 100%|██████████| 5/5 [00:00<00:00, 57.29it/s]\n",
      "Encoding: 100%|██████████| 5/5 [00:00<00:00, 61.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report on SVM: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000         2\n",
      "           1     0.6000    1.0000    0.7500         3\n",
      "\n",
      "    accuracy                         0.6000         5\n",
      "   macro avg     0.3000    0.5000    0.3750         5\n",
      "weighted avg     0.3600    0.6000    0.4500         5\n",
      "\n",
      "T5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Encoding text: 100%|██████████| 5/5 [00:00<00:00, 160.11it/s]\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Encoding text: 100%|██████████| 5/5 [00:00<00:00, 131.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report on SVM: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000         2\n",
      "           1     0.6000    1.0000    0.7500         3\n",
      "\n",
      "    accuracy                         0.6000         5\n",
      "   macro avg     0.3000    0.5000    0.3750         5\n",
      "weighted avg     0.3600    0.6000    0.4500         5\n",
      "\n",
      "GPT2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding: 100%|██████████| 5/5 [00:00<00:00, 48.94it/s]\n",
      "Encoding: 100%|██████████| 5/5 [00:00<00:00, 59.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report on SVM: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000         2\n",
      "           1     0.5000    0.6667    0.5714         3\n",
      "\n",
      "    accuracy                         0.4000         5\n",
      "   macro avg     0.2500    0.3333    0.2857         5\n",
      "weighted avg     0.3000    0.4000    0.3429         5\n",
      "\n",
      "Processing dataset: stanfordnlp/imdb, instruction: 'Review Analysis: '\n",
      "Bert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding: 100%|██████████| 5/5 [00:00<00:00, 134.80it/s]\n",
      "Encoding: 100%|██████████| 5/5 [00:00<00:00, 145.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report on SVM: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000         2\n",
      "           1     0.5000    0.6667    0.5714         3\n",
      "\n",
      "    accuracy                         0.4000         5\n",
      "   macro avg     0.2500    0.3333    0.2857         5\n",
      "weighted avg     0.3000    0.4000    0.3429         5\n",
      "\n",
      "Bert2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding: 100%|██████████| 5/5 [00:00<00:00, 51.12it/s]\n",
      "Encoding: 100%|██████████| 5/5 [00:00<00:00, 54.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report on SVM: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5000    0.5000    0.5000         2\n",
      "           1     0.6667    0.6667    0.6667         3\n",
      "\n",
      "    accuracy                         0.6000         5\n",
      "   macro avg     0.5833    0.5833    0.5833         5\n",
      "weighted avg     0.6000    0.6000    0.6000         5\n",
      "\n",
      "Instructor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding: 100%|██████████| 5/5 [00:00<00:00, 54.72it/s]\n",
      "Encoding: 100%|██████████| 5/5 [00:00<00:00, 56.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report on SVM: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000         2\n",
      "           1     0.6000    1.0000    0.7500         3\n",
      "\n",
      "    accuracy                         0.6000         5\n",
      "   macro avg     0.3000    0.5000    0.3750         5\n",
      "weighted avg     0.3600    0.6000    0.4500         5\n",
      "\n",
      "T5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Encoding text: 100%|██████████| 5/5 [00:00<00:00, 155.65it/s]\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Encoding text: 100%|██████████| 5/5 [00:00<00:00, 127.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report on SVM: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000         2\n",
      "           1     0.6000    1.0000    0.7500         3\n",
      "\n",
      "    accuracy                         0.6000         5\n",
      "   macro avg     0.3000    0.5000    0.3750         5\n",
      "weighted avg     0.3600    0.6000    0.4500         5\n",
      "\n",
      "GPT2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding: 100%|██████████| 5/5 [00:00<00:00, 46.92it/s]\n",
      "Encoding: 100%|██████████| 5/5 [00:00<00:00, 61.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report on SVM: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000         2\n",
      "           1     0.5000    0.6667    0.5714         3\n",
      "\n",
      "    accuracy                         0.4000         5\n",
      "   macro avg     0.2500    0.3333    0.2857         5\n",
      "weighted avg     0.3000    0.4000    0.3429         5\n",
      "\n",
      "Processing dataset: stanfordnlp/imdb, instruction: 'Represent the Review sentence for classifying emotion as positive or negative: '\n",
      "Bert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding: 100%|██████████| 5/5 [00:00<00:00, 168.40it/s]\n",
      "Encoding: 100%|██████████| 5/5 [00:00<00:00, 174.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report on SVM: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000         2\n",
      "           1     0.5000    0.6667    0.5714         3\n",
      "\n",
      "    accuracy                         0.4000         5\n",
      "   macro avg     0.2500    0.3333    0.2857         5\n",
      "weighted avg     0.3000    0.4000    0.3429         5\n",
      "\n",
      "Bert2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding: 100%|██████████| 5/5 [00:00<00:00, 64.76it/s]\n",
      "Encoding: 100%|██████████| 5/5 [00:00<00:00, 59.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report on SVM: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5000    0.5000    0.5000         2\n",
      "           1     0.6667    0.6667    0.6667         3\n",
      "\n",
      "    accuracy                         0.6000         5\n",
      "   macro avg     0.5833    0.5833    0.5833         5\n",
      "weighted avg     0.6000    0.6000    0.6000         5\n",
      "\n",
      "Instructor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding: 100%|██████████| 5/5 [00:00<00:00, 53.77it/s]\n",
      "Encoding: 100%|██████████| 5/5 [00:00<00:00, 58.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report on SVM: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000         2\n",
      "           1     0.6000    1.0000    0.7500         3\n",
      "\n",
      "    accuracy                         0.6000         5\n",
      "   macro avg     0.3000    0.5000    0.3750         5\n",
      "weighted avg     0.3600    0.6000    0.4500         5\n",
      "\n",
      "T5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Encoding text: 100%|██████████| 5/5 [00:00<00:00, 137.55it/s]\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Encoding text: 100%|██████████| 5/5 [00:00<00:00, 106.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report on SVM: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000         2\n",
      "           1     0.6000    1.0000    0.7500         3\n",
      "\n",
      "    accuracy                         0.6000         5\n",
      "   macro avg     0.3000    0.5000    0.3750         5\n",
      "weighted avg     0.3600    0.6000    0.4500         5\n",
      "\n",
      "GPT2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding: 100%|██████████| 5/5 [00:00<00:00, 39.39it/s]\n",
      "Encoding: 100%|██████████| 5/5 [00:00<00:00, 61.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report on SVM: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000         2\n",
      "           1     0.5000    0.6667    0.5714         3\n",
      "\n",
      "    accuracy                         0.4000         5\n",
      "   macro avg     0.2500    0.3333    0.2857         5\n",
      "weighted avg     0.3000    0.4000    0.3429         5\n",
      "\n",
      "Processing dataset: stanfordnlp/imdb, instruction: 'Evaluate the sentiment of the movie review sentence: '\n",
      "Bert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding: 100%|██████████| 5/5 [00:00<00:00, 122.39it/s]\n",
      "Encoding: 100%|██████████| 5/5 [00:00<00:00, 142.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report on SVM: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000         2\n",
      "           1     0.6000    1.0000    0.7500         3\n",
      "\n",
      "    accuracy                         0.6000         5\n",
      "   macro avg     0.3000    0.5000    0.3750         5\n",
      "weighted avg     0.3600    0.6000    0.4500         5\n",
      "\n",
      "Bert2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding: 100%|██████████| 5/5 [00:00<00:00, 50.81it/s]\n",
      "Encoding: 100%|██████████| 5/5 [00:00<00:00, 58.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report on SVM: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5000    0.5000    0.5000         2\n",
      "           1     0.6667    0.6667    0.6667         3\n",
      "\n",
      "    accuracy                         0.6000         5\n",
      "   macro avg     0.5833    0.5833    0.5833         5\n",
      "weighted avg     0.6000    0.6000    0.6000         5\n",
      "\n",
      "Instructor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding: 100%|██████████| 5/5 [00:00<00:00, 57.44it/s]\n",
      "Encoding: 100%|██████████| 5/5 [00:00<00:00, 60.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report on SVM: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000         2\n",
      "           1     0.6000    1.0000    0.7500         3\n",
      "\n",
      "    accuracy                         0.6000         5\n",
      "   macro avg     0.3000    0.5000    0.3750         5\n",
      "weighted avg     0.3600    0.6000    0.4500         5\n",
      "\n",
      "T5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Encoding text: 100%|██████████| 5/5 [00:00<00:00, 156.56it/s]\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Encoding text: 100%|██████████| 5/5 [00:00<00:00, 109.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report on SVM: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000         2\n",
      "           1     0.5000    0.6667    0.5714         3\n",
      "\n",
      "    accuracy                         0.4000         5\n",
      "   macro avg     0.2500    0.3333    0.2857         5\n",
      "weighted avg     0.3000    0.4000    0.3429         5\n",
      "\n",
      "GPT2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding: 100%|██████████| 5/5 [00:00<00:00, 46.34it/s]\n",
      "Encoding: 100%|██████████| 5/5 [00:00<00:00, 58.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report on SVM: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000         2\n",
      "           1     0.6000    1.0000    0.7500         3\n",
      "\n",
      "    accuracy                         0.6000         5\n",
      "   macro avg     0.3000    0.5000    0.3750         5\n",
      "weighted avg     0.3600    0.6000    0.4500         5\n",
      "\n",
      "Processing dataset: stanfordnlp/imdb, instruction: 'Analyze the review to determine if the sentiment is positive or negative: '\n",
      "Bert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding: 100%|██████████| 5/5 [00:00<00:00, 117.21it/s]\n",
      "Encoding: 100%|██████████| 5/5 [00:00<00:00, 128.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report on SVM: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000         2\n",
      "           1     0.5000    0.6667    0.5714         3\n",
      "\n",
      "    accuracy                         0.4000         5\n",
      "   macro avg     0.2500    0.3333    0.2857         5\n",
      "weighted avg     0.3000    0.4000    0.3429         5\n",
      "\n",
      "Bert2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding: 100%|██████████| 5/5 [00:00<00:00, 44.40it/s]\n",
      "Encoding: 100%|██████████| 5/5 [00:00<00:00, 52.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report on SVM: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5000    0.5000    0.5000         2\n",
      "           1     0.6667    0.6667    0.6667         3\n",
      "\n",
      "    accuracy                         0.6000         5\n",
      "   macro avg     0.5833    0.5833    0.5833         5\n",
      "weighted avg     0.6000    0.6000    0.6000         5\n",
      "\n",
      "Instructor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding: 100%|██████████| 5/5 [00:00<00:00, 55.25it/s]\n",
      "Encoding: 100%|██████████| 5/5 [00:00<00:00, 57.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report on SVM: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000         2\n",
      "           1     0.6000    1.0000    0.7500         3\n",
      "\n",
      "    accuracy                         0.6000         5\n",
      "   macro avg     0.3000    0.5000    0.3750         5\n",
      "weighted avg     0.3600    0.6000    0.4500         5\n",
      "\n",
      "T5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Encoding text: 100%|██████████| 5/5 [00:00<00:00, 150.51it/s]\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Encoding text: 100%|██████████| 5/5 [00:00<00:00, 129.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report on SVM: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000         2\n",
      "           1     0.6000    1.0000    0.7500         3\n",
      "\n",
      "    accuracy                         0.6000         5\n",
      "   macro avg     0.3000    0.5000    0.3750         5\n",
      "weighted avg     0.3600    0.6000    0.4500         5\n",
      "\n",
      "GPT2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding: 100%|██████████| 5/5 [00:00<00:00, 42.19it/s]\n",
      "Encoding: 100%|██████████| 5/5 [00:00<00:00, 58.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report on SVM: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000         2\n",
      "           1     0.5000    0.6667    0.5714         3\n",
      "\n",
      "    accuracy                         0.4000         5\n",
      "   macro avg     0.2500    0.3333    0.2857         5\n",
      "weighted avg     0.3000    0.4000    0.3429         5\n",
      "\n",
      "Processing dataset: stanfordnlp/imdb, instruction: 'Determine the emotional tone of the review for sentiment classification: '\n",
      "Bert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding: 100%|██████████| 5/5 [00:00<00:00, 139.62it/s]\n",
      "Encoding: 100%|██████████| 5/5 [00:00<00:00, 141.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report on SVM: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000         2\n",
      "           1     0.6000    1.0000    0.7500         3\n",
      "\n",
      "    accuracy                         0.6000         5\n",
      "   macro avg     0.3000    0.5000    0.3750         5\n",
      "weighted avg     0.3600    0.6000    0.4500         5\n",
      "\n",
      "Bert2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding: 100%|██████████| 5/5 [00:00<00:00, 51.18it/s]\n",
      "Encoding: 100%|██████████| 5/5 [00:00<00:00, 69.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report on SVM: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5000    0.5000    0.5000         2\n",
      "           1     0.6667    0.6667    0.6667         3\n",
      "\n",
      "    accuracy                         0.6000         5\n",
      "   macro avg     0.5833    0.5833    0.5833         5\n",
      "weighted avg     0.6000    0.6000    0.6000         5\n",
      "\n",
      "Instructor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding: 100%|██████████| 5/5 [00:00<00:00, 56.48it/s]\n",
      "Encoding: 100%|██████████| 5/5 [00:00<00:00, 59.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report on SVM: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000         2\n",
      "           1     0.6000    1.0000    0.7500         3\n",
      "\n",
      "    accuracy                         0.6000         5\n",
      "   macro avg     0.3000    0.5000    0.3750         5\n",
      "weighted avg     0.3600    0.6000    0.4500         5\n",
      "\n",
      "T5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Encoding text: 100%|██████████| 5/5 [00:00<00:00, 152.39it/s]\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Encoding text: 100%|██████████| 5/5 [00:00<00:00, 143.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report on SVM: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000         2\n",
      "           1     0.6000    1.0000    0.7500         3\n",
      "\n",
      "    accuracy                         0.6000         5\n",
      "   macro avg     0.3000    0.5000    0.3750         5\n",
      "weighted avg     0.3600    0.6000    0.4500         5\n",
      "\n",
      "GPT2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding: 100%|██████████| 5/5 [00:00<00:00, 58.67it/s]\n",
      "Encoding: 100%|██████████| 5/5 [00:00<00:00, 58.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report on SVM: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000         2\n",
      "           1     0.6000    1.0000    0.7500         3\n",
      "\n",
      "    accuracy                         0.6000         5\n",
      "   macro avg     0.3000    0.5000    0.3750         5\n",
      "weighted avg     0.3600    0.6000    0.4500         5\n",
      "\n",
      "Processing dataset: stanfordnlp/imdb, instruction: 'Classify the given movie review as either positive or negative: '\n",
      "Bert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding: 100%|██████████| 5/5 [00:00<00:00, 179.66it/s]\n",
      "Encoding: 100%|██████████| 5/5 [00:00<00:00, 184.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report on SVM: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000         2\n",
      "           1     0.6000    1.0000    0.7500         3\n",
      "\n",
      "    accuracy                         0.6000         5\n",
      "   macro avg     0.3000    0.5000    0.3750         5\n",
      "weighted avg     0.3600    0.6000    0.4500         5\n",
      "\n",
      "Bert2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding: 100%|██████████| 5/5 [00:00<00:00, 56.10it/s]\n",
      "Encoding: 100%|██████████| 5/5 [00:00<00:00, 75.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report on SVM: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5000    0.5000    0.5000         2\n",
      "           1     0.6667    0.6667    0.6667         3\n",
      "\n",
      "    accuracy                         0.6000         5\n",
      "   macro avg     0.5833    0.5833    0.5833         5\n",
      "weighted avg     0.6000    0.6000    0.6000         5\n",
      "\n",
      "Instructor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding: 100%|██████████| 5/5 [00:00<00:00, 52.58it/s]\n",
      "Encoding: 100%|██████████| 5/5 [00:00<00:00, 58.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report on SVM: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000         2\n",
      "           1     0.6000    1.0000    0.7500         3\n",
      "\n",
      "    accuracy                         0.6000         5\n",
      "   macro avg     0.3000    0.5000    0.3750         5\n",
      "weighted avg     0.3600    0.6000    0.4500         5\n",
      "\n",
      "T5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Encoding text: 100%|██████████| 5/5 [00:00<00:00, 155.66it/s]\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Encoding text: 100%|██████████| 5/5 [00:00<00:00, 133.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report on SVM: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000         2\n",
      "           1     0.6000    1.0000    0.7500         3\n",
      "\n",
      "    accuracy                         0.6000         5\n",
      "   macro avg     0.3000    0.5000    0.3750         5\n",
      "weighted avg     0.3600    0.6000    0.4500         5\n",
      "\n",
      "GPT2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding: 100%|██████████| 5/5 [00:00<00:00, 34.73it/s]\n",
      "Encoding: 100%|██████████| 5/5 [00:00<00:00, 53.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report on SVM: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000         2\n",
      "           1     0.6000    1.0000    0.7500         3\n",
      "\n",
      "    accuracy                         0.6000         5\n",
      "   macro avg     0.3000    0.5000    0.3750         5\n",
      "weighted avg     0.3600    0.6000    0.4500         5\n",
      "\n",
      "{'Instructions': ['None', 'GS1', 'GS2', 'GS3', 'GS4', 'GS5', 'GL1', 'GL2', 'GL3', 'GL4', 'GL5', 'S1', 'S2', 'S3', 'S4', 'S5', 'L1', 'L2', 'L3', 'L4', 'L5'], 'Bert': [0.4, 0.6, 0.6, 0.6, 0.4, 0.4, 0.4, 0.4, 0.6, 0.4, 0.6, 0.4, 0.6, 0.4, 0.4, 0.4, 0.6, 0.4, 0.6, 0.6], 'Bert-large': [0.6, 0.4, 0.6, 0.4, 0.4, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6], 'Instructor': [0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6], 'T5': [0.6, 0.4, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.4, 0.6, 0.6, 0.6, 0.4, 0.6, 0.6, 0.6], 'GPT2': [0.4, 0.4, 0.4, 0.4, 0.4, 0.4, 0.4, 0.6, 0.6, 0.6, 0.4, 0.4, 0.4, 0.4, 0.4, 0.4, 0.6, 0.4, 0.6, 0.6]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "instructions_map = {\n",
    "    'stanfordnlp/imdb': instructions_imdb,\n",
    "    'yelp_review_full': instructions_yelp,\n",
    "    'Voice49/arXiv-Abstract-Label-20k': instructions_arXiv\n",
    "}\n",
    "\n",
    "datasets = ['stanfordnlp/imdb', \n",
    "            'yelp_review_full',\n",
    "            'Voice49/arXiv-Abstract-Label-20k']\n",
    "\n",
    "evaluator = ['SVM', 'MLP']\n",
    "\n",
    "train, test = get_dataset(datasets[0], train_size=1000, test_size=1000)\n",
    "\n",
    "# Data structure to record accuracies\n",
    "data = {\n",
    "    \"Instructions\": [\"None\", \"GS1\", \"GS2\", \"GS3\", \"GS4\", \"GS5\", \"GL1\", \"GL2\", \"GL3\", \"GL4\", \"GL5\", \n",
    "                     \"S1\", \"S2\", \"S3\", \"S4\", \"S5\", \"L1\", \"L2\", \"L3\", \"L4\", \"L5\"],\n",
    "    \"Bert\": [],\n",
    "    \"Bert-large\": [],\n",
    "    \"Instructor\": [],\n",
    "    \"T5\": [],\n",
    "    \"GPT2\": []\n",
    "}\n",
    "\n",
    "# Loop last dataset\n",
    "for dataset in datasets[:1]:\n",
    "    instructions = instructions_general + instructions_map[dataset]\n",
    "    for instruction in instructions:\n",
    "        print(f\"Processing dataset: {dataset}, instruction: '{instruction}'\")\n",
    "\n",
    "        print(\"Bert\")\n",
    "        accB1 = EmbedFlow_Bert_1(train, test, evaluator[0], instruction)\n",
    "        data[\"Bert\"].append(accB1)\n",
    "\n",
    "        print(\"Bert2\")\n",
    "        accB2 = EmbedFlow_Bert_2(train, test, evaluator[0], instruction)\n",
    "        data[\"Bert-large\"].append(accB2)\n",
    "\n",
    "        print(\"Instructor\")\n",
    "        accI = EmbedFlow_Instructor(train, test, evaluator[0], instruction)\n",
    "        data[\"Instructor\"].append(accI)\n",
    "\n",
    "        print(\"T5\")\n",
    "        accT = EmbedFlow_T5(train, test, evaluator[0], instruction)\n",
    "        data[\"T5\"].append(accT)\n",
    "\n",
    "        print(\"GPT2\")\n",
    "        accG = EmbedFlow_GPT(train, test, evaluator[0], instruction)\n",
    "        data[\"GPT2\"].append(accG)\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Display the DataFrame\n",
    "# print(df)\n",
    "\n",
    "# Visualizing the data using appropriate plots\n",
    "plt.figure(figsize=(14, 8))\n",
    "\n",
    "for column in df.columns[1:]:\n",
    "    plt.plot(df[\"Instructions\"], df[column], marker='o', label=column)\n",
    "\n",
    "plt.title(\"Classifier Accuracy on Text Embedding Models with Instructions\")\n",
    "plt.xlabel(\"Instructions\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend(loc='upper center', bbox_to_anchor=(1.02, 1))\n",
    "plt.grid(True)\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate statistics\n",
    "statistics = {}\n",
    "for column in df.columns[1:]:\n",
    "    with_instructions = df[column][1:]\n",
    "    without_instructions = df[column][0]\n",
    "    mean_with = with_instructions.mean()\n",
    "    std_with = with_instructions.std()\n",
    "    change = mean_with - without_instructions\n",
    "    statistics[column] = {\n",
    "        'Base': without_instructions,\n",
    "        'Mean (Inst)': mean_with,\n",
    "        'Std (Inst)': std_with,\n",
    "        'Diff': change\n",
    "    }\n",
    "\n",
    "# Display the statistics\n",
    "stats_df = pd.DataFrame(statistics).T\n",
    "print(stats_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "embed",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
